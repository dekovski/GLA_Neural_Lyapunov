{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyO9etfvgbTy5yjn1B00NjOZ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dekovski/GLA_Neural_Lyapunov/blob/main/Example1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Example 1: 2d system**"
      ],
      "metadata": {
        "id": "Es9kUa1OMoqg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install nangs\n",
        "!pip install torchdiffeq"
      ],
      "metadata": {
        "id": "VlapWshSBosG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T7xr48LXA4QY"
      },
      "outputs": [],
      "source": [
        "import sympy as sp\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "import nangs\n",
        "import math\n",
        "\n",
        "\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "nangs.__version__, torch.__version__"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Build your own set of eigenfunctions\n",
        "x,y = sp.symbols('x y', real=True)\n",
        "p1 = -x + x**3\n",
        "p2 = y - y**3\n",
        "phi1 = (p1 + 2*p2);\n",
        "phi2 = (2*p1 - 3*p2);\n",
        "phi = sp.Matrix([phi1,phi2]);\n",
        "J = phi.jacobian([x,y]);\n",
        "f = sp.simplify(J.inv()*sp.Matrix([[-0.8,0],[0,-1.2]])*phi)\n",
        "F = f.jacobian([x,y])\n",
        "\n",
        "# Linear and nonlinear parts of the dynamics\n",
        "A = F.subs([(x,0),(y,0)])\n",
        "fn = f - A*sp.Matrix([x,y])\n",
        "E,W = np.linalg.eig(np.array(A.T).astype(np.float64))\n",
        "w1 = W[:,0]; w2 = W[:,1]\n",
        "l1 = E[0]; l2 = E[1]\n",
        "\n",
        "# Relevant functions used for computation/comparision\n",
        "p1= sp.lambdify((x,y),phi1)\n",
        "p2= sp.lambdify((x,y),phi2)\n",
        "#g1 = np.dot(w1,fn)[0]; g2 = np.dot(w2,fn)[0]\n",
        "g1 = np.dot(w1,[x,y]) ; g2 = np.dot(w2,[x,y]);\n",
        "g1 = sp.lambdify((x,y),g1); g2 = sp.lambdify((x,y),g2)\n",
        "f = sp.lambdify((x,y),tuple(f))"
      ],
      "metadata": {
        "id": "jedNI2hvYY3s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1.1. EDMD for local approximation"
      ],
      "metadata": {
        "id": "yZc8LjhX-QvQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# -*- coding: utf-8 -*-\n",
        "from sympy.polys.orderings import monomial_key\n",
        "from sympy.polys.monomials import itermonomials\n",
        "from numpy.linalg import inv, eig, pinv, det\n",
        "from scipy.linalg import svd, svdvals, sqrtm\n",
        "from numpy import diag, dot, real, imag\n",
        "from IPython import display\n",
        "import torch\n",
        "\n",
        "np.random.seed(10)\n",
        "torch.manual_seed(0)\n",
        "\n",
        "# Sample data within epsilon nbhd\n",
        "def sample_data(dic,N,T, eps):\n",
        "    X = np.empty((T*N,2))\n",
        "    Y = np.empty((T*N,2))\n",
        "    thetas = 2*np.pi*np.random.rand(N)\n",
        "    r = np.random.rand(N)\n",
        "    P = eps*np.stack([r,r],axis=1)*np.stack([np.sin(thetas),np.cos(thetas)],axis=1)\n",
        "    Start = P\n",
        "    for k in range(T):\n",
        "        X[k*N:(k+1)*N,:] = P\n",
        "        P = P + dt*np.array(f(P[:,0],P[:,1])).T\n",
        "        Y[k*N:(k+1)*N,:] = P\n",
        "    X = basis_fun(X.T)\n",
        "    Y = basis_fun(Y.T)\n",
        "    return X,Y, Start\n",
        "\n",
        "# Dictionary of monomials for EDMD, deg = 10 i.e. 66 total dictionary functions\n",
        "def basis_fun(X):\n",
        "    ret = np.ones((len(monomials),X.shape[1]))\n",
        "    ret[1:,:] = np.array(basis(X[0],X[1])[1:])\n",
        "    return ret[1:,:]\n",
        "\n",
        "deg = 3\n",
        "monomials = sorted(itermonomials([x, y], deg), key=monomial_key('grlex', [y, x]))\n",
        "basis = sp.lambdify((x,y),monomials,\"numpy\")\n",
        "\n",
        "# EDMD\n",
        "N = 100; T=1000; eps = 0.05; dt=0.01\n",
        "X,Y,Start = sample_data(basis_fun,N,T,eps=eps)\n",
        "\n",
        "Fphi = np.eye(X.shape[0])\n",
        "Xtr = X.copy()\n",
        "Ytr = Y.copy()\n",
        "\n",
        "while(Xtr.shape[0]>4):\n",
        "    A = np.matmul(Ytr,np.linalg.pinv(Xtr))\n",
        "    mu,phi = eig(A.T)\n",
        "    res_eig = np.abs(np.matmul(phi.T,Ytr - np.matmul(A,Xtr)))\n",
        "    res_eig = np.max(res_eig,axis=1)\n",
        "    #print(np.sort(res_eig))\n",
        "    s = np.argsort(res_eig)\n",
        "    phi = phi[:,s]\n",
        "    m = Xtr.shape[0]\n",
        "    m = int(m/2)\n",
        "    phi = phi[:,0:m]\n",
        "    Fphi = np.matmul(Fphi,phi)\n",
        "    Xtr = np.matmul(Fphi.T,X)\n",
        "    Ytr = np.matmul(Fphi.T,Y)\n",
        "\n",
        "A = np.matmul(Ytr,np.linalg.pinv(Xtr))\n",
        "mu,phi = eig(A.T)\n",
        "lam = np.log(mu)/dt\n",
        "K = np.diag(mu)\n",
        "phi = np.matmul(Fphi,phi)\n",
        "res_eig = np.abs(np.matmul(phi.T,Y) - np.matmul(K.T,np.matmul(phi.T,X)))\n",
        "res_eig = np.max(res_eig,axis=1)\n",
        "#print(np.sort(res_eig))\n",
        "\n",
        "# Get the stable eigenmodes\n",
        "stable = np.argwhere(real(lam)<0).T[0]\n",
        "phi_stable = phi[:,stable]\n",
        "lam_stable = lam[stable]\n",
        "sort_idx = np.argsort(real(lam_stable))\n",
        "phi_stable = phi_stable[:,sort_idx]\n",
        "lam_stable = lam_stable[sort_idx]\n",
        "\n",
        "g = sp.Matrix(real(phi_stable.T)*(abs(real(phi_stable.T))>1e-3))*sp.Matrix(monomials[1:])"
      ],
      "metadata": {
        "id": "KOPOk-Yl-Pv_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Use these analytical experssions later for comparision\n",
        "print(phi1)     # Actual eigenfunction to be learnt\n",
        "print(-g[-1])   #Local EDMD approximation of phi1 (mind the sign and scaling).\n",
        "\n",
        "print(lam_stable[-1]) #Eigenvalue approximated by EDMD (should be roughly -0.8)"
      ],
      "metadata": {
        "id": "V-oURSpq4GNw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Define the eigenfunction PDE\n",
        "\n",
        "from nangs import PDE\n",
        "l1 = real(lam_stable[-1]); # Learnt from EDMD\n",
        "g1 = sp.lambdify((x,y),g[-1]) # Learnt from EDMD\n",
        "\n",
        "class Eigen(PDE):\n",
        "    def computePDELoss(self, inputs, outputs):\n",
        "\n",
        "        # compute gradients\n",
        "        grads = self.computeGrads(outputs, inputs)\n",
        "\n",
        "        # compute loss\n",
        "        dpdx, dpdy = grads[:, 0], grads[:, 1]\n",
        "        x, y = inputs[:, 0], inputs[:, 1]\n",
        "        p = outputs\n",
        "        u, v = f(x, y)\n",
        "        return {'pde': 0.01*(-l1*p + u*dpdx + v*dpdy)}\n",
        "\n",
        "# instantiate pde\n",
        "pde = Eigen(inputs=('x', 'y'), outputs='p')"
      ],
      "metadata": {
        "id": "pll_x5zzCgV7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1.2. Prepare training data using GLA"
      ],
      "metadata": {
        "id": "ijyOK4dV-CXW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# define the sampler\n",
        "\n",
        "from nangs import RandomSampler\n",
        "\n",
        "eps=0.45\n",
        "sampler = RandomSampler({\n",
        "    'x': [-eps, eps],\n",
        "    'y': [-eps, eps],\n",
        "}, device=device, n_samples=1000)\n",
        "\n",
        "pde.set_sampler(sampler)"
      ],
      "metadata": {
        "id": "rApv7tnKF2yu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torchdiffeq import odeint\n",
        "from nangs import Dirichlet\n",
        "\n",
        "box = {}\n",
        "for i in range(2):\n",
        "  box[pde.inputs[i]]=[-eps, eps]\n",
        "\n",
        "H = lambda t,X : torch.vstack(f(*tuple(X[0:-1])) + (((1/(t+1e-5))*(-X[-1] + np.exp(-l1*t)*g1(*tuple(X[0:-1])))),))\n",
        "samples_per_face = 100\n",
        "T = 100.\n",
        "X_box = torch.empty(0)\n",
        "Y_box = torch.empty(0)\n",
        "for i in range(2):\n",
        "  #Face A\n",
        "  dic=box #This is not a deep copy, caution!\n",
        "  dic[pde.inputs[i]]=[eps,eps]\n",
        "  X_ = tuple(torch.rand(samples_per_face, )*(lims[1] - lims[0]) + lims[0] for var, lims in dic.items())\n",
        "  Y_ = odeint(H, torch.vstack(X_ + (torch.zeros(samples_per_face, ),)), torch.tensor([0.,T]))[-1][-1]\n",
        "  Y_box = torch.hstack((Y_box,Y_))\n",
        "  X_box = torch.hstack((X_box, torch.vstack(X_)))\n",
        "  #Face B\n",
        "  dic=box\n",
        "  dic[pde.inputs[i]]=[-eps,-eps]\n",
        "  X_ = tuple(torch.rand(samples_per_face, )*(lims[1] - lims[0]) + lims[0] for var, lims in dic.items())\n",
        "  Y_ = odeint(H, torch.vstack(X_ + (torch.zeros(samples_per_face),)), torch.tensor([0.,T]))[-1][-1]\n",
        "  Y_box = torch.hstack((Y_box,Y_))\n",
        "  X_box = torch.hstack((X_box, torch.vstack(X_)))\n",
        "  dic[pde.inputs[i]]=[-eps,eps]\n",
        "\n",
        "#Interior\n",
        "samples_interior = 1000\n",
        "X_ = tuple(torch.rand(samples_interior, )*(lims[1] - lims[0]) + lims[0] for var, lims in dic.items())\n",
        "Y_ = odeint(H, torch.vstack(X_ + (torch.zeros(samples_interior),)), torch.tensor([0.,T]))[-1][-1]\n",
        "Y_box = torch.hstack((Y_box,Y_))\n",
        "X_box = torch.hstack((X_box, torch.vstack(X_)))\n",
        "\n",
        "class Dirichlet(nangs.bocos.boco.Boco):\n",
        "  def __init__(self, X_box, Y_box, name=\"dirichlet\"):\n",
        "      super().__init__(name)\n",
        "      self.X_ = X_box.T\n",
        "      self.Y_ = Y_box\n",
        "\n",
        "  def validate(self, inputs, outputs):\n",
        "      super().validate()\n",
        "\n",
        "  def computeLoss(self, model, criterion, inputs, outputs):\n",
        "      y_hat = model(self.X_)[:,0]\n",
        "      y = self.Y_\n",
        "      return {self.name: criterion(y, y_hat)}\n",
        "\n",
        "initial_condition = Dirichlet(X_box.to(device),Y_box.to(device),\"faces\")\n",
        "pde.add_boco(initial_condition)"
      ],
      "metadata": {
        "id": "oHmkaR8E72kw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1.3. Train"
      ],
      "metadata": {
        "id": "aUAF4uPMownt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# solve\n",
        "from nangs import MLP\n",
        "\n",
        "LR = 1e-2\n",
        "N_STEPS = 2000\n",
        "NUM_LAYERS = 2\n",
        "NUM_HIDDEN = 128\n",
        "\n",
        "mlp = MLP(len(pde.inputs), len(pde.outputs), NUM_LAYERS, NUM_HIDDEN).to(device)\n",
        "optimizer = torch.optim.Adam(mlp.parameters())\n",
        "scheduler = torch.optim.lr_scheduler.OneCycleLR(optimizer, max_lr=LR, pct_start=0.1, div_factor=10, final_div_factor=1, total_steps=N_STEPS)\n",
        "\n",
        "pde.compile(mlp, optimizer, scheduler)\n",
        "%time hist = pde.solve(N_STEPS)"
      ],
      "metadata": {
        "id": "Mk34jFJfIDvF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# plot loss history\n",
        "import pandas as pd\n",
        "\n",
        "df = pd.DataFrame(hist)\n",
        "fig = plt.figure(dpi=100)\n",
        "ax = plt.subplot(1,1,1)\n",
        "ax.set_yscale('log')\n",
        "df.plot(ax=ax, grid=True)"
      ],
      "metadata": {
        "id": "q8b55y7GoINv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1.4. Evaluate"
      ],
      "metadata": {
        "id": "6OwrSI9iorXL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from mpl_toolkits.mplot3d import Axes3D\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib import cm\n",
        "\n",
        "Nd=100\n",
        "x = np.linspace(-0.45,0.45,Nd)\n",
        "y = np.linspace(-0.45,0.45,Nd)\n",
        "\n",
        "_x, _y = np.meshgrid(x, y)\n",
        "\n",
        "grid = np.stack(np.meshgrid(x, y), -1).reshape(-1, 2)\n",
        "X = torch.from_numpy(grid).float().to(device)\n",
        "p = pde.eval(X)\n",
        "p = p.cpu().numpy().reshape((len(_y),len(_x)))\n",
        "\n",
        "z_train = Y_box.detach().numpy()\n",
        "xy_train = X_box.detach().numpy()"
      ],
      "metadata": {
        "id": "kbL5oh3pCZYz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1.5. Visualize"
      ],
      "metadata": {
        "id": "ITsG1P-Me9mk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import plotly.graph_objects as go\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "#fig = go.Figure(data=[go.Surface(z=(-w1[0]/2)*(2*_x**3+3*_y**3), x=_x, y=_y, showscale=False, opacity=0.3), go.Surface(z=p, x=_x, y=_y) ])\n",
        "fig = go.Figure(data=[go.Surface(z=-0.38*(_x**3 - _x - 2*_y**3 + 2*_y), x=_x, y=_y, showscale=True, opacity=0.5,colorbar=dict(lenmode='fraction', len=0.6, thickness=18)), # <-- Actual eigenfunction\n",
        "                      go.Scatter3d(x = xy_train[0,:], y = xy_train[1,:], z = z_train, mode = 'markers', marker = dict(size = 1.5, color = 'black')), # <-- GLA generated training data\n",
        "                      #go.Surface(z=p, x=_x, y=_y, opacity=0.3, colorbar=dict(lenmode='fraction', len=0.6, thickness=18)) # <-- DNN eigenfunction\n",
        "                      ])\n",
        "\n",
        "fig.update_layout(title='Actual vs learnt eigenfunction',\n",
        "                  autosize=True,\n",
        "                  width=600, height=600,\n",
        "                  margin=dict(l=0, r=0, b=15, t=30))\n",
        "\n",
        "fig.update_layout(scene = dict(\n",
        "                    xaxis_title='x1',\n",
        "                    yaxis_title='x2',\n",
        "                    zaxis_title='g*(x)'))\n",
        "fig.update_layout(scene_aspectmode='cube')\n",
        "fig.update_coloraxes(colorbar_xpad=0)\n",
        "fig.show()\n"
      ],
      "metadata": {
        "id": "p1Q9L4_zPA2F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Save if all looks A-OK !\n",
        "from google.colab import files\n",
        "torch.save(mlp.state_dict(),'checkpoint_GLA.pth')\n",
        "files.download('checkpoint_GLA.pth')"
      ],
      "metadata": {
        "id": "KDKtpZ9DZ58O"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}